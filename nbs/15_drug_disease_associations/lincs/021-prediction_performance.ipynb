{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044577,
     "end_time": "2020-12-18T22:38:21.345879",
     "exception": false,
     "start_time": "2020-12-18T22:38:21.301302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011764,
     "end_time": "2020-12-18T22:38:21.398073",
     "exception": false,
     "start_time": "2020-12-18T22:38:21.386309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011799,
     "end_time": "2020-12-18T22:38:21.422136",
     "exception": false,
     "start_time": "2020-12-18T22:38:21.410337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modules loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.022467,
     "end_time": "2020-12-18T22:38:21.456126",
     "exception": false,
     "start_time": "2020-12-18T22:38:21.433659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.192251,
     "end_time": "2020-12-18T22:38:21.659996",
     "exception": false,
     "start_time": "2020-12-18T22:38:21.467745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011416,
     "end_time": "2020-12-18T22:38:21.683356",
     "exception": false,
     "start_time": "2020-12-18T22:38:21.671940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TISSUES = 49\n",
    "# N_TISSUES = 1\n",
    "N_THRESHOLDS = 5\n",
    "N_PREDICTIONS = 646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = conf.RESULTS[\"DRUG_DISEASE_ANALYSES\"] / \"lincs\"\n",
    "display(OUTPUT_DIR)\n",
    "assert OUTPUT_DIR.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PREDICTIONS_DIR = Path(OUTPUT_DIR, \"predictions\", \"dotprod_neg\")\n",
    "display(OUTPUT_PREDICTIONS_DIR)\n",
    "OUTPUT_PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PharmacotherapyDB gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard = pd.read_pickle(\n",
    "    Path(conf.RESULTS[\"DRUG_DISEASE_ANALYSES\"], \"gold_standard.pkl\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard[\"true_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard[\"true_class\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load drug-disease predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction_files = list(OUTPUT_PREDICTIONS_DIR.glob(\"*.h5\"))\n",
    "display(len(current_prediction_files))\n",
    "\n",
    "assert len(current_prediction_files) == 2 * (\n",
    "    N_TISSUES * N_THRESHOLDS\n",
    ")  # two methods (single-gene and module-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for f in tqdm(current_prediction_files, ncols=100):\n",
    "    # FIXME: it shouldn't be necessary to include this anymore\n",
    "    # exclude S-MultiXcan results, since they have no direction of effect\n",
    "    if f.name.startswith(\"smultixcan-\"):\n",
    "        continue\n",
    "\n",
    "    prediction_data = pd.read_hdf(f, key=\"prediction\")\n",
    "    prediction_data = pd.merge(\n",
    "        prediction_data, gold_standard, on=[\"trait\", \"drug\"], how=\"inner\"\n",
    "    )\n",
    "\n",
    "    metadata = pd.read_hdf(f, key=\"metadata\")\n",
    "\n",
    "    prediction_data[\"score\"] = prediction_data[\"score\"].rank()\n",
    "    prediction_data[\"trait\"] = prediction_data[\"trait\"].astype(\"category\")\n",
    "    prediction_data[\"drug\"] = prediction_data[\"drug\"].astype(\"category\")\n",
    "\n",
    "    prediction_data = prediction_data.assign(method=metadata.method.values[0])\n",
    "    prediction_data[\"method\"] = prediction_data[\"method\"].astype(\"category\")\n",
    "\n",
    "    prediction_data = prediction_data.assign(n_top_genes=metadata.n_top_genes.values[0])\n",
    "    #     prediction_data[\"n_top_genes\"] = prediction_data[\"data\"].astype(\"category\")\n",
    "\n",
    "    prediction_data = prediction_data.assign(data=metadata.data.values[0])\n",
    "    prediction_data[\"data\"] = prediction_data[\"data\"].astype(\"category\")\n",
    "\n",
    "    predictions.append(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(pred.shape[0] == N_PREDICTIONS for pred in predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat(predictions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(predictions.shape)\n",
    "\n",
    "assert predictions.shape[0] == 2 * (N_TISSUES * N_THRESHOLDS) * N_PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not predictions.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = predictions[\"method\"].value_counts()\n",
    "display(_tmp)\n",
    "\n",
    "assert _tmp.loc[\"Gene-based\"] == N_TISSUES * N_THRESHOLDS * N_PREDICTIONS\n",
    "assert _tmp.loc[\"Module-based\"] == N_TISSUES * N_THRESHOLDS * N_PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = predictions.groupby([\"method\", \"n_top_genes\"]).count()\n",
    "display(_tmp)\n",
    "\n",
    "assert np.all(_tmp == N_TISSUES * N_PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: add this to the 011 notebooks... or maybe it's fine here (after submitting draft)\n",
    "def _get_tissue(x):\n",
    "    if x.endswith(\"-projection\"):\n",
    "        return x.split(\"spredixcan-mashr-zscores-\")[1].split(\"-projection\")[0]\n",
    "    else:\n",
    "        return x.split(\"spredixcan-mashr-zscores-\")[1].split(\"-data\")[0]\n",
    "\n",
    "\n",
    "predictions = predictions.assign(tissue=predictions[\"data\"].apply(_get_tissue))\n",
    "\n",
    "# # FIXME: remove or better document; here just for the most_signif version\n",
    "# predictions = predictions.assign(tissue=\"most_signif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = predictions.groupby([\"method\", \"tissue\"]).count()\n",
    "display(_tmp)\n",
    "\n",
    "assert np.all(_tmp.loc[\"Gene-based\"] == (N_PREDICTIONS * N_THRESHOLDS))\n",
    "assert np.all(_tmp.loc[\"Module-based\"] == (N_PREDICTIONS * N_THRESHOLDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all prediction tables should have the same shape\n",
    "predictions_shape = (\n",
    "    predictions.groupby([\"method\", \"n_top_genes\", \"tissue\"])\n",
    "    .apply(lambda x: x.shape)\n",
    "    .unique()\n",
    ")\n",
    "display(predictions_shape)\n",
    "\n",
    "assert predictions_shape.shape[0] == 1\n",
    "assert predictions_shape[0][0] == N_PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = Path(OUTPUT_DIR, \"predictions\", \"predictions_results.pkl\").resolve()\n",
    "display(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_pickle(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce_mean(x):\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"score\": x[\"score\"].mean(),\n",
    "            \"true_class\": x[\"true_class\"].unique()[0]\n",
    "            #             if x[\"true_class\"].unique().shape[0] == 1\n",
    "            #             else None,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def _reduce_max(x):\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"score\": x[\"score\"].max(),\n",
    "            \"true_class\": x[\"true_class\"].unique()[0]\n",
    "            #             if x[\"true_class\"].unique().shape[0] == 1\n",
    "            #             else None,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# def _reduce_best(x):\n",
    "# #     assert x[\"true_class\"].unique() == FINISH\n",
    "#     x_stand = (x[\"score\"] - x[\"score\"].mean()) / x[\"score\"].std()\n",
    "\n",
    "#     x_max_score = x_stand.max()\n",
    "#     x_min_score = x_stand.min()\n",
    "\n",
    "#     # select best score\n",
    "#     x_selected = x[\"score\"].max()\n",
    "#     if abs(x_min_score) > abs(x_max_score):\n",
    "#         x_selected = x[\"score\"].min()\n",
    "\n",
    "#     return pd.Series(\n",
    "#         {\n",
    "#             \"score\": x_selected,\n",
    "#             \"true_class\": x[\"true_class\"].unique()[0]\n",
    "#             #             if x[\"true_class\"].unique().shape[0] == 1\n",
    "#             #             else None,\n",
    "#         }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_avg = (\n",
    "    predictions.groupby([\"trait\", \"drug\", \"method\", \"tissue\"])\n",
    "    #     predictions.groupby([\"trait\", \"drug\", \"method\"])\n",
    "    .apply(_reduce_mean)\n",
    "    .dropna()\n",
    "    .groupby([\"trait\", \"drug\", \"method\"])\n",
    "    .apply(_reduce_max)\n",
    "    .dropna()\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_avg should have twice the number of rows in the predictions table, since has both methods\n",
    "display(predictions_avg.shape)\n",
    "assert predictions_avg.shape[0] == int(predictions_shape[0][0] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictions_avg.dropna().shape == predictions_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = Path(\n",
    "    OUTPUT_DIR, \"predictions\", \"predictions_results_aggregated.pkl\"\n",
    ").resolve()\n",
    "display(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_avg.to_pickle(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by method/n_top_genes\n",
    "predictions.groupby([\"method\", \"tissue\", \"n_top_genes\"]).apply(\n",
    "    lambda x: roc_auc_score(x[\"true_class\"], x[\"score\"])\n",
    ").groupby([\"method\", \"n_top_genes\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by method/tissue\n",
    "predictions.groupby([\"method\", \"tissue\", \"n_top_genes\"]).apply(\n",
    "    lambda x: roc_auc_score(x[\"true_class\"], x[\"score\"])\n",
    ").groupby([\"method\", \"tissue\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_avg.groupby([\"method\"]).apply(\n",
    "    lambda x: roc_auc_score(x[\"true_class\"], x[\"score\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by method/n_top_genes\n",
    "predictions.groupby([\"method\", \"tissue\", \"n_top_genes\"]).apply(\n",
    "    lambda x: average_precision_score(x[\"true_class\"], x[\"score\"])\n",
    ").groupby([\"method\", \"n_top_genes\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by method/tissue\n",
    "predictions.groupby([\"method\", \"tissue\", \"n_top_genes\"]).apply(\n",
    "    lambda x: average_precision_score(x[\"true_class\"], x[\"score\"])\n",
    ").groupby([\"method\", \"tissue\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_avg.groupby([\"method\"]).apply(\n",
    "    lambda x: average_precision_score(x[\"true_class\"], x[\"score\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all,-execution,-papermill,-trusted",
   "formats": "ipynb,py//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4334.257345,
   "end_time": "2020-12-18T23:50:34.771313",
   "environment_variables": {},
   "exception": null,
   "input_path": "15_drug_disease_associations/000-spredixcan_most_significant.ipynb",
   "output_path": "15_drug_disease_associations/000-spredixcan_most_significant.run.ipynb",
   "parameters": {},
   "start_time": "2020-12-18T22:38:20.513968",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
