{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pressing-decade",
   "metadata": {
    "papermill": {
     "duration": 0.022374,
     "end_time": "2021-03-10T00:10:54.143712",
     "exception": false,
     "start_time": "2021-03-10T00:10:54.121338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-latter",
   "metadata": {
    "papermill": {
     "duration": 0.022374,
     "end_time": "2021-03-10T00:10:54.143712",
     "exception": false,
     "start_time": "2021-03-10T00:10:54.121338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It runs GLSPhenoplier to compute an association between each selected LV and PhenomeXcan trait. Traits of interest are selected from the \"complex branch\" (clustering results), and LVs are those predicted (by a decision tree classifier) to be discriminative for those clusters in the \"complex branch\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-raise",
   "metadata": {
    "papermill": {
     "duration": 0.022374,
     "end_time": "2021-03-10T00:10:54.143712",
     "exception": false,
     "start_time": "2021-03-10T00:10:54.121338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-audit",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-logan",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-practitioner",
   "metadata": {
    "papermill": {
     "duration": 0.038647,
     "end_time": "2021-03-10T00:10:54.205009",
     "exception": false,
     "start_time": "2021-03-10T00:10:54.166362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_JOBS = conf.GENERAL[\"N_JOBS\"]\n",
    "display(N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-chart",
   "metadata": {
    "papermill": {
     "duration": 0.029926,
     "end_time": "2021-03-10T00:10:54.259533",
     "exception": false,
     "start_time": "2021-03-10T00:10:54.229607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env MKL_NUM_THREADS=$N_JOBS\n",
    "%env OPEN_BLAS_NUM_THREADS=$N_JOBS\n",
    "%env NUMEXPR_NUM_THREADS=$N_JOBS\n",
    "%env OMP_NUM_THREADS=$N_JOBS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-charleston",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-wrong",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gls import GLSPhenoplier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-swing",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-destruction",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = conf.RESULTS[\"GLS\"]\n",
    "display(OUTPUT_DIR)\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-inspector",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_FILENAME = OUTPUT_DIR / \"gls_phenotypes-phenomexcan.pkl\"\n",
    "display(OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-knife",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-colonial",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PhenomeXcan (S-MultiXcan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-threshold",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_SUBSET = \"z_score_std\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-india",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_STEM = \"projection-smultixcan-efo_partial-mashr-zscores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-frequency",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_filepath = Path(\n",
    "    conf.RESULTS[\"DATA_TRANSFORMATIONS_DIR\"],\n",
    "    INPUT_SUBSET,\n",
    "    f\"{INPUT_SUBSET}-{INPUT_STEM}.pkl\",\n",
    ").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-protest",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(input_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-accused",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-courage",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-retrieval",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-private",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONSENSUS_CLUSTERING_DIR = Path(\n",
    "    conf.RESULTS[\"CLUSTERING_DIR\"], \"consensus_clustering\"\n",
    ").resolve()\n",
    "\n",
    "display(CONSENSUS_CLUSTERING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-anniversary",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file = Path(CONSENSUS_CLUSTERING_DIR, \"best_partitions_by_k.pkl\").resolve()\n",
    "display(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-concord",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_partitions = pd.read_pickle(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-portugal",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_partitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-queensland",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_partitions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-remedy",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MultiPLIER summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-intensity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multiplier_model_summary = pd.read_pickle(conf.MULTIPLIER[\"MODEL_SUMMARY_FILE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-count",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multiplier_model_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-second",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multiplier_model_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-donna",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "well_aligned_lvs = multiplier_model_summary[\n",
    "    (multiplier_model_summary[\"FDR\"] < 0.05) | (multiplier_model_summary[\"AUC\"] >= 0.75)\n",
    "]\n",
    "\n",
    "display(well_aligned_lvs.shape)\n",
    "display(well_aligned_lvs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-samba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "well_aligned_lv_codes = set([f\"LV{lvi}\" for lvi in well_aligned_lvs[\"LV index\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-istanbul",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(well_aligned_lv_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-submission",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(well_aligned_lv_codes)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-browser",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Select partition / cluster pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-jungle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This dictionary specifies in the keys the partition/clusters where traits will be selected from.\n",
    "# To select the LVs, we will take those LVs that are discriminative for the partition/cluster in the key,\n",
    "# but we also include an additional set of partition/clusters since there is a hierarchy of clustering solutions,\n",
    "# one LV in those might have not been present in the original partition/cluster tuple. This is manually inferred\n",
    "# by looking at the clustering tree. For example, within the \"complex branch\", we have the partition/cluster tuple\n",
    "# (29,11), including coronary artery disease and other traits. This tuple has a set of (at most) 20 LVs that are\n",
    "# discriminative for these traits. However, at k=26, this tuple is a children of (26,13) (which is a parent of (29,16)),\n",
    "# which has another set of discriminative LVs. We also take those ones for (29,11).\n",
    "#\n",
    "# key: a tuple (partition_k or ID, cluster_id)\n",
    "# value: a list of tuples (each tuple having two elements: (partition_k or ID, cluster_id))\n",
    "PHENOTYPES_LVS_CONFIG = {\n",
    "    # cardiovascular\n",
    "    (29, 14): [(16, 15)],\n",
    "    (29, 16): [(26, 13), (16, 15)],\n",
    "    (29, 11): [(26, 13), (16, 15)],\n",
    "    (29, 21): [(26, 25), (22, 0), (16, 15)],\n",
    "    (29, 17): [],\n",
    "    # autoimmune\n",
    "    (29, 8): [(25, 18), (22, 8)],\n",
    "    (29, 26): [(25, 12), (25, 18), (22, 8)],\n",
    "    (29, 13): [(25, 12), (22, 8)],\n",
    "    # keratometry\n",
    "    (29, 10): [],\n",
    "    # heel bone mineral density\n",
    "    (29, 15): [],\n",
    "    # hapiness\n",
    "    (29, 27): [],\n",
    "    # asthma\n",
    "    # (29, 12): [],\n",
    "    # neutrophils\n",
    "    (29, 9): [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-spice",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLUSTER_LV_DIR = conf.RESULTS[\"CLUSTERING_INTERPRETATION\"][\"BASE_DIR\"] / \"cluster_lvs\"\n",
    "assert CLUSTER_LV_DIR.exists()\n",
    "\n",
    "display(CLUSTER_LV_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-aside",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_lvs_data(part_k, cluster_idx):\n",
    "    \"\"\"\n",
    "    For a partition/cluster pair, it returns a list of LV names that are discriminative for that cluster.\n",
    "    \"\"\"\n",
    "    cluster_lvs = pd.read_pickle(\n",
    "        CLUSTER_LV_DIR\n",
    "        / f\"part{part_k}\"\n",
    "        / f\"cluster_interpreter-part{part_k}_k{cluster_idx}.pkl\"\n",
    "    )\n",
    "\n",
    "    return list(cluster_lvs[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-departure",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_get_lvs_data(29, 11)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-secretary",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GLSPhenoplier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-characteristic",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get list of phenotypes/lvs pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-namibia",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here I get a list of phenotype/lv pairs to run GLSPhenoplier on. I do this because I don't need to train the model\n",
    "for all LVs and all traits. The pairs are read from the `PHENOTYPES_LVS_CONFIG` dictionary specified before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-liquid",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phenotypes_lvs_pairs = []\n",
    "\n",
    "for (part_k, cluster_id), extra_for_lvs in PHENOTYPES_LVS_CONFIG.items():\n",
    "    # get traits from the partition/cluster\n",
    "    part = best_partitions.loc[part_k, \"partition\"]\n",
    "    cluster_traits = data.index[part == cluster_id]\n",
    "\n",
    "    # get first the LVs that are predictive for this partition/cluster\n",
    "    # then, add extra LVs from the partition/cluster \"parents\" specified in\n",
    "    # PHENOTYPES_LVS_CONFIG as a list of values\n",
    "    lv_list = _get_lvs_data(part_k, cluster_id)\n",
    "\n",
    "    for extra_part_k, extra_cluster_id in extra_for_lvs:\n",
    "        extra_lv_list = _get_lvs_data(part_k, cluster_id)\n",
    "        lv_list.extend(extra_lv_list)\n",
    "\n",
    "    # now create the list of trait/lv pairs where GLSPhenoplier will be run on later\n",
    "    for phenotype_code in cluster_traits:\n",
    "        for lv_code in lv_list:\n",
    "            phenotypes_lvs_pairs.append(\n",
    "                {\n",
    "                    \"phenotype_part_k\": part_k,\n",
    "                    \"phenotype_cluster_id\": cluster_id,\n",
    "                    \"phenotype\": phenotype_code,\n",
    "                    \"lv\": lv_code,\n",
    "                }\n",
    "            )\n",
    "\n",
    "phenotypes_lvs_pairs = pd.DataFrame(phenotypes_lvs_pairs).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-intro",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phenotypes_lvs_pairs = phenotypes_lvs_pairs.sort_values(\"phenotype\").reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-korean",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phenotypes_lvs_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-october",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phenotypes_lvs_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-aircraft",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-pixel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "pbar = tqdm(total=phenotypes_lvs_pairs.shape[0])\n",
    "\n",
    "for idx, row in phenotypes_lvs_pairs.iterrows():\n",
    "    phenotype_code = row[\"phenotype\"]\n",
    "    lv_code = row[\"lv\"]\n",
    "\n",
    "    pbar.set_description(f\"{phenotype_code} - {lv_code}\")\n",
    "\n",
    "    gls_model = GLSPhenoplier(\n",
    "        smultixcan_result_set_filepath=conf.PHENOMEXCAN[\n",
    "            \"SMULTIXCAN_EFO_PARTIAL_MASHR_ZSCORES_FILE\"\n",
    "        ]\n",
    "    )\n",
    "    gls_model.fit_named(lv_code, phenotype_code)\n",
    "    res = gls_model.results\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"part_k\": row[\"phenotype_part_k\"],\n",
    "            \"cluster_id\": row[\"phenotype_cluster_id\"],\n",
    "            \"phenotype\": phenotype_code,\n",
    "            \"lv\": lv_code,\n",
    "            \"lv_with_pathway\": lv_code in well_aligned_lv_codes,\n",
    "            \"coef\": res.params.loc[\"lv\"],\n",
    "            \"pvalue\": res.pvalues_onesided.loc[\"lv\"],\n",
    "            \"pvalue_twosided\": res.pvalues.loc[\"lv\"],\n",
    "            \"summary\": gls_model.results_summary,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # save results every 10 models trained\n",
    "    if (idx % 10) == 0:\n",
    "        pd.DataFrame(results).to_pickle(OUTPUT_FILENAME)\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-wrapping",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-fellowship",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-console",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-newark",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.sort_values(\"pvalue\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-facility",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-amino",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.to_pickle(OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-namibia",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all,-execution,-papermill,-trusted",
   "formats": "ipynb,py//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
